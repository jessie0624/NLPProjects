# 召回方法记录和分析

## 1. 数据集分析:
    数据集100000 条，即100k个问题-答案 pair。
    custom问题的长度： 平均长度23个字符，最长157，50% 18个字符以内，75%都在29以内。所以整个问题与问题的匹配是一个短句子匹配模型。
        mean         22.715907
        std          16.989520
        min           6.000000
        25%          11.000000
        50%          18.000000
        75%          29.000000
        max         157.000000

run_model1.py : 没有加倒排索引。 查询问题，得到答案的时间是 0.233s 
run_model2.py: 添加倒排索引。查询问题，得到答案的时间是0.3-0.8s根据不同的问题查询时间不一样。每个问题都会去先建立相似问题表，然后再进行搜索。 在小数据集上没有体现出优势。
run_model3.py: 采用HNSW对w2v句向量进行索引。得到答案的时间是0.015s-0.02
run_model4.py:　采用HNSW对SIF句向量进行索引。

## 各个模型的结果总结
1. TFIDF 经过一轮轮数据清洗，结果达到99.9% 唯一不能召回的一个是 “催哈单” 这个单词不在词典库里面，所有TFIDF无法匹配。 

2. LSI 结果也达到99.9% 无法召回的原因与TFIDF一致。

3. LDA 结果只有98.1%  对于 比较偏理 检索主题的问题 无法召回. 即用户问句是句子与整个客服问答不匹配的。

4. word2vec w/o tfidf 作为权重 计算句向量。
    参数设置：min_count = 2, window=2, negative=15,
    without tfidf weight:
    - w2v epoch 10时，不加tfidf 权重， 召回率98.3%。
    - w2v epoch 15时, 不加tfidf 权重， 召回率为 98%. 

    不加tfidf权重时 召回错误的很多都是句子比较长的，超过25单词的句子。

    with tfidf weight:
    - w2v epcoh 3时， 加上tfidf权重，召回率为 98.1% 
    - w2v epoch 5时， 加上tfidf权重，召回率为 98.2%
    - w2v epoch 10时，加上tfidf权重，召回率为 98.1%
    - w2v epoch 15时，加上tfidf权重，召回率为 98.1%  只提升了0.1%
    
    参数设置min_count=1, windows=2, negative=15
    - w2v epoch 3时， 加上tfidf权重， 召回率为 
    - w2v epoch 5时， 加上tfidf权重， 召回率为 98%
    - w2v epoch 10时， 加上tfidf权重， 召回率为 98.2%
    - w2v epoch 15时， 加上tfidf权重， 召回率为

5. SIF + word2vec + 去除主成分 + HNSW  top10召回率99.6% (没有去除停用词)
   total 3917k effective words， 去除stopwords之后 top10召回率是98.2%




## 下面进行召回分析：

召回分析的方法是，用建立index的数据集  的一部分做为eval的数据，输入模型，看召回前10个结果里面 是否有正确的index。 通过前5万数据集进行召回建模， 用前1000个数据集作为召回验证。

### 方法1 使用TFIDF 实现简单的问答

    缺点：TFIDF 全完根据 词语 来召回，相似度也是看 输入问题 与index里面有没有共同的 词语，有的话相似度高，没有则找不到。无法实现对同义词的理解等。 
    拟补：可以人工添加同义词，切分词语后，根据用户输入的句子，进行同意词替换 得到一些相似句子，再进行搜索，将多次搜索的结果和并

    step-1 直接用原始数据集，通过前5万数据集进行召回建模。 结果 87.3% 惨不忍睹。 
            分析原因： 1. 数据集重复的太多，召回的index虽然与target index不一样，但是内容确实很接近，所以需要去重复。
    step-2 去重后 数据由原来260450 减少到174961， 去重后召回率达到97.6%。
            分析错误原因：1. 错误召回数据显示，错误召回的问题简短没有意义的。下一步我们清理掉这些没意义的custom的话
                “怎样     是的是的   可以的啊   通过了  可以吗  可以  多少相数的  哦哦   嗯。  是这个”
    step-3 清楚短的无意义的custom话语。  top10召回率达到了99.9%！   
           分析错误原因：下面错误是错误召回的：“催哈单”  这个就是TFIDF BOW的表达的问题所有在，只能匹配到含有相同单词的句子，对于意思相近 但是不同的表达方法 就会出错。那为什么连同一个index也无法检索出来呢？因为TFIDF里面没有这个“催哈单”没有这个词语，所以无法召回。

           你可以催哈单么 ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']

           让我们输入 催单的 句子：
           请输入问题(q退出): 你帮 我催下单吧
                亲，我们给您找到的答案是： 亲爱哒，请问还有其他问题我能为您效劳的吗?  
                same questions： 能帮我催催吗,                score： 0.8575009703636169
                same questions： 麻烦您帮我催催,                score： 0.8216080069541931
                same questions： 好吧，，帮我催催，谢谢,                score： 0.8176972270011902
                same questions： 那你那边能帮我催一下吗,                score： 0.8022392988204956
                same questions： 帮我跟催一下,                score： 0.8022392988204956
                Time cost: 0.10715532302856445 s
            请输入问题(q退出): 催单
                亲，我们给您找到的答案是： 这边只能帮您提交纠纷单催促商家处理
                same questions： 要不你们帮我催单,                score： 0.8788083791732788
                same questions： [数字x]号已催单,                score： 0.7602860331535339
                same questions： 对的，我现在急用，所以想催单,                score： 0.7081878781318665
                same questions： 是[SEP]我要催单[SEP]急用,                score： 0.7025554776191711
                same questions： 能不能再帮我催催单,                score： 0.6870310306549072
                Time cost: 0.13613629341125488 s

### 方法2. LSI 主题模型

理论解释可以参考： https://www.cnblogs.com/pinard/p/6805861.html

step-1 直接运行， 召回率74.3% 
    错误分析：  错误召回的问题 经过分词后 缺少了问的目的 比如 问题: "发票是纸质的吗？" 召回相似问题中 确实是 发票和纸质两个类型的，但是有些是陈述句 比如 "麻烦开纸质发票"   这个明显与 query的问题 不一样。 
    于是查询stopwords 去除stopwords里面的 为什么，是什么，吗， 呢， 怎么，如何， 哪天/年，啥，怎样，？等一系列疑问助词和符号。

step-2: 去除stopwords中的疑问词语之后，召回率达到99.9%
    错误分析：最主要的还是 “催哈单” 这个里面添加了口语的表达，无法与 正常的 催单 催等得到相似的匹配。 所以问题在于如何处理口语表达？这个与TFIDF的类似。

    你可以催哈单么 ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']


### 方法3. LDA 主题模型

理论分析： https://www.cnblogs.com/pinard/p/6244265.html 

step-1: 直接运行 召回到达97.5%。
    错误分析：
    LDA 召回错误的，一般都是 用户的问题 与 整个客服系统 不太相关的问题,或者词频比较低的词语无法突出。

    错误召回： 对于这些问题 语义相似，只是没有完全index匹配，问题还是在预料，冗余太多，清除语料里面冗余的问题。就可以解决。
        好的，谢谢! 
        ['好的，明白了，谢谢', '好的明白了谢谢', '好的明白了，谢谢', '好吧!那谢谢了', '好的，明白了。谢谢', '好的谢谢啦!', 'a好的，谢谢!', '好的，明白了，谢谢。', '哦，好的明白了谢谢', '好，明白了，谢谢']

    错误召回：这些问题 相对来说没有很强的业务性质， 所以没有召回成功，主要原因是LDA 是主题聚类的
        那帮我有的先发吧 
        爱你哦么么哒 
        还是要自己配 
        能认识你，也是我的荣幸 
            ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']

    错误召回问题：## 对于这个错误的召回 主要是 [时间x] 这个有很大的影响。如何降低这些词的影响？ 其实不是[时间x]影响大，而是jieba分词时 把这个分开了 并且stopwords里面[ 和 ] 也被去除了 所以导致 预处理之初的 替换词 影响变大了。所以 我们需要在jiabe分词里面添加 user_dict 把 替换的词 添加进去  数字x，订单x等
        您好，明天只有是在[时间x]才能购买 
        ['[金额x]号我都要上班通班', 
        '第二个是纳税人识别号[SEP]咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x]', 
        '这个我需要明天[金额x]号安装', 
        '[订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]][SEP]您好[SEP]您好',
        '我申请退款[SEP]现在还需要我反馈[SEP]怎么反馈啊[SEP]我都拍了照片了[SEP]咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x][SEP]如何反馈?',
        '手机屏幕失灵了，去哪里修理[SEP][订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]]', 
        '咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x][SEP]我的快递到配送站了。我过几天去自提可以吗?', 
        '纳税识别号:[数字x]F[SEP]申请售后订单编号:[订单x]下单时间:[日期x][时间x][SEP]上面这个是激光笔的订单号', 
        '[订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]][SEP]我怎样修改增票资质[SEP]您好[SEP]您好', 
        '东西是奶要不就等明天送了[SEP][日期x][时间x]订单编号:[数字x]订单金额:￥[金额x]']

step-2: 首先 jieba分词user_dict里面添加 替换词 不能切分。 然后，清除对话里面的冗余的相似问题。

    1. 添加user_dict后，lda 召回率97.7%

    2. 去除相似的  去除之后  98.1% (一些只包含 谢谢，好的 这种字样的 custom 句子) 共去除了515行。
    
    错误分析：
    wrong recall
    你可以催哈单么 | 体脂秤是电池的？ | 当然啊[SEP]等着呢 | 长虹和美菱共用的 | 就这样吧，涮我倒霉 | 啤酒[SEP]百威 | 那帮我有的先发吧  | 爱你哦么么哒  | 还是要自己配 | 能认识你，也是我的荣幸 | 不需要了，谢谢您 
        ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']
    好的[SEP]谢谢  | 对[SEP]可以  | 好的[姓名x] |好的[SEP]谢谢呢 
    没[SEP]谢谢 | 没有了[SEP]谢谢 
        ['其他没有了，[SEP]谢谢', '没有了谢谢[SEP]五星', '没有啦[SEP]谢谢你', 'OK，谢谢[SEP]没有了', '没有了这些[SEP]谢谢', '没有了，我就静候佳音吧[SEP]谢谢', '没有了，[SEP]谢谢', '没有了，等你的信[SEP]谢谢', '谢谢🙏[SEP]没有了', 'ok，没有了[SEP]谢谢']

    。。。[数字x]天也太久了。 
        ['[数字x]天了呀', '嗯，就他自己生成的就是[数字x]天的吧', '超过[数字x]天了', '[数字x]天了', '那就延[数字x]天', '[数字x]W多', 'g[数字x]e', '[数字x]天', '[数字x]W', '北宿矿安居北区[数字x]号楼']



### 方法4： word2vec + tfidf　权重　召回率99.9%

相同的问题在TOP10里面可以准确召回，但是需要分析召回其他的内容 是否真的相似。
唯一的一个错误召回，只是index与query不一样而已，内容其实一样。
recall : 0.999

    2020-11-12 18:35:13 - INFO - sentenceSimilarity - recall_at_10: 0.999
    wrong recall
    没有了，谢谢
    ['没有，谢谢。', '没有其他了，谢谢。', '没有了，谢谢啦。', '谢谢，没有了', '没有了，谢谢哦', '谢谢啦，没有了', '没有。谢谢你', '没有了。谢谢你了。', '谢谢，没有啦', '其他没有，谢谢']


    用户输入体验：
    请输入问题(q退出): 我 的订单啥时候发呀
    2020-11-12 19:51:11 - INFO - sentenceSimilarity - Searching for 我的订单啥时候发呀
    2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - collecting document frequencies
    2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - PROGRESS: processing document #0
    2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - calculating IDF weights for 10000 documents and 3125 features (63731 matrix non-zeros)
    [(77, 1), (350, 1)] [(77, 0.37828451813959335), (350, 0.9256893773485227)]
    ['订单', '啥时候', '发呀']
    亲，我们给您找到的答案是： [站点x]您的订单正在配送途中，请您准备签收(配送员:[姓名x]，电话:[电话x])，感谢您的耐心等待。[SEP]这个已经邮寄到了呢[SEP]您这边直接联系配送就是可以的哈
    Time cost: 0.016529321670532227 s
    same questions： 是这一个订单~,                distance: 0.0005517895333468914
    same questions： 你好，订单的发票别忘了,                distance: 0.0011370766442269087
    same questions： [订单x][SEP]很忙吗?,                distance: 0.0022505568340420723
    same questions： 这个订单签收了,                distance: 0.002779792295768857
    same questions： 如果收货人信息,                distance: 0.002916591241955757

- 子问题: word2vec 词向量训练过拟合

    print(w2v_model.most_similar('退货'，))
    print(w2v_model.most_similar('降价'))
    print(w2v_model.most_similar('发货'))
    print(w2v_model.most_similar('催单'))
    print(w2v_model.most_similar('催'))

    [('还', 0.9969998002052307), ('退', 0.9965711832046509), ('处理', 0.9958178400993347), ('怎么', 0.9949917793273926), ('今天', 0.9944421052932739), ('货', 0.994336724281311), ('客服', 0.9942106008529663), ('已经', 0.9928359985351562), ('拒收', 0.9926967024803162), ('明天', 0.9922024011611938)]
    [('价格', 0.9973174333572388), ('昨天', 0.9970822334289551), ('差价', 0.9967004060745239), ('到货', 0.9964430332183838), ('保护', 0.9957348108291626), ('没收', 0.9951258301734924), ('退', 0.9950886964797974), ('拍', 0.9949791431427002), ('成功', 0.9946277141571045), ('大概', 0.9943530559539795)]
    [('显示', 0.999091625213623), ('什么', 0.9982945919036865), ('货', 0.9978306889533997), ('已经', 0.9973732233047485), ('收到', 0.9972431063652039), ('配送', 0.9972000122070312), ('昨天', 0.996067464351654), ('签收', 0.9959815740585327), ('没收', 0.9954724907875061), ('确认', 0.9953488111495972)]
    [('没来', 0.9999058246612549), ('手里', 0.9998915195465088), ('库房', 0.9998910427093506), ('三点', 0.9998835921287537), ('发起', 0.9998757839202881), ('赔偿', 0.999871015548706), ('交给', 0.9998658895492554), ('问过', 0.9998571872711182), ('特殊', 0.9998517036437988), ('我该', 0.999845564365387)]
    [('派送', 0.9966047406196594), ('尽快', 0.9961134195327759), ('签收', 0.9957507252693176), ('配送', 0.9949312806129456), ('收到', 0.994855523109436), ('已经', 0.9947052001953125), ('麻烦', 0.9946165084838867), ('问', 0.9945946931838989), ('安排', 0.9944000840187073), ('送到', 0.9943376779556274)]

### 所以召回结果的评估？

对于召回的内容如何评估，可以用文本相似度匹配模型。进行召回结果的分析。