# 召回方法记录和分析

数据集100000 条，即100k个问题-答案 pair。
run_model1.py : 没有加倒排索引。 查询问题，得到答案的时间是 0.233s
run_model2.py: 添加倒排索引。查询问题，得到答案的时间是0.12s-0.2s根据不同的问题查询时间不一样。但是都比model1的短。
run_model3.py: 采用HNSW对w2v句向量进行索引。得到答案的时间是0.015s-0.02

## 各个模型的结果总结
1. TFIDF 经过一轮轮数据清洗，结果达到99.9%
2. LSI 结果也达到99.9%
3. LDA 结果只有98.1%  对于 比较偏理检索主题的问题 无法召回。
4. word2vec + tfidf 作为权重 计算句向量。 99.9% 召回率. 用户体验更好，包容性更强，对于词典里没有词语 也可以给出相对比较合适的回复。



## 下面进行召回分析：
    找回分析的方法是，用建立index的数据集  的一部分做为eval的数据，输入模型，看召回前10个结果里面 是否有正确的index。 通过前5万数据集进行召回建模， 用前1000个数据集作为召回验证。

### 方法1 使用TFIDF 实现简单的问答

    缺点：TFIDF 全完根据 词语 来召回，相似度也是看 输入问题 与index里面有没有共同的 词语，有的话相似度高，没有则找不到。无法实现对同义词的理解等。 
    拟补：可以人工添加同义词，切分词语后，根据用户输入的句子，进行同意词替换 得到一些相似句子，再进行搜索，将多次搜索的结果和并

    step-1 直接用原始数据集，通过前5万数据集进行召回建模。 结果 87.3% 惨不忍睹。 
            分析原因： 1. 数据集重复的太多，召回的index虽然与target index不一样，但是内容确实很接近，所以需要去重复。
    step-2 去重后 数据由原来260450 减少到174961， 去重后召回率达到97.6%。
            分析错误原因：1. 错误召回数据显示，错误召回的问题简短没有意义的。下一步我们清理掉这些没意义的custom的话
                “怎样     是的是的   可以的啊   通过了  可以吗  可以  多少相数的  哦哦   嗯。  是这个”
    step-3 清楚短的无意义的custom话语。  top10召回率达到了99.9%！   
           分析错误原因：下面错误是错误召回的：“催哈单”  这个就是TFIDF BOW的表达的问题所有在，只能匹配到含有相同单词的句子，对于意思相近 但是不同的表达方法 就会出错。那为什么连同一个index也无法检索出来呢？

           你可以催哈单么 ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']

           让我们输入 催单的 句子：
           请输入问题(q退出): 你帮 我催下单吧
                亲，我们给您找到的答案是： 亲爱哒，请问还有其他问题我能为您效劳的吗?  
                same questions： 能帮我催催吗,                score： 0.8575009703636169
                same questions： 麻烦您帮我催催,                score： 0.8216080069541931
                same questions： 好吧，，帮我催催，谢谢,                score： 0.8176972270011902
                same questions： 那你那边能帮我催一下吗,                score： 0.8022392988204956
                same questions： 帮我跟催一下,                score： 0.8022392988204956
                Time cost: 0.10715532302856445 s
            请输入问题(q退出): 催单
                亲，我们给您找到的答案是： 这边只能帮您提交纠纷单催促商家处理
                same questions： 要不你们帮我催单,                score： 0.8788083791732788
                same questions： [数字x]号已催单,                score： 0.7602860331535339
                same questions： 对的，我现在急用，所以想催单,                score： 0.7081878781318665
                same questions： 是[SEP]我要催单[SEP]急用,                score： 0.7025554776191711
                same questions： 能不能再帮我催催单,                score： 0.6870310306549072
                Time cost: 0.13613629341125488 s

### 方法2. LSI 主题模型

理论解释可以参考： https://www.cnblogs.com/pinard/p/6805861.html

step-1 直接运行， 召回率74.3% 
    错误分析：  错误召回的问题 经过分词后 缺少了问的目的 比如 问题: "发票是纸质的吗？" 召回相似问题中 确实是 发票和纸质两个类型的，但是有些是陈述句 比如 "麻烦开纸质发票"   这个明显与 query的问题 不一样。 

    于是查询stopwords 去除stopwords里面的 为什么，是什么，吗， 呢， 怎么，如何， 哪天/年，啥，怎样，？等一系列疑问助词和符号。

step-2: 去除stopwords中的疑问词语之后，召回率达到99.9%
    错误分析：最主要的还是 “催哈单” 这个里面添加了口语的表达，无法与 正常的 催单 催等得到相似的匹配。 所以问题在于如何处理口语表达？这个与TFIDF的类似。
    你可以催哈单么 ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']


### 方法3. LDA 主题模型

理论分析： https://www.cnblogs.com/pinard/p/6244265.html 

step-1: 直接运行 召回到达97.5%。
    错误分析：
    LDA 召回错误的，一般都是 用户的问题 与 整个客服系统 不太相关的问题。

    错误召回： 对于这些问题 语义相似，只是没有完全index匹配，问题还是在预料，冗余太多，清除语料里面冗余的问题。就可以解决。
        好的，谢谢! 
        ['好的，明白了，谢谢', '好的明白了谢谢', '好的明白了，谢谢', '好吧!那谢谢了', '好的，明白了。谢谢', '好的谢谢啦!', 'a好的，谢谢!', '好的，明白了，谢谢。', '哦，好的明白了谢谢', '好，明白了，谢谢']

    错误召回：这些问题 相对来说没有很强的业务性质， 所以没有召回成功，主要原因是LDA 是主题聚类的
        那帮我有的先发吧 
        爱你哦么么哒 
        还是要自己配 
        能认识你，也是我的荣幸 
            ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']

    错误召回问题：## 对于这个错误的召回 主要是 [时间x] 这个有很大的影响。如何降低这些词的影响？ 其实不是[时间x]影响大，而是jieba分词时 把这个分开了 并且stopwords里面[ 和 ] 也被去除了 所以导致 预处理之初的 替换词 影响变大了。所以 我们需要在jiabe分词里面添加 user_dict 把 替换的词 添加进去  数字x，订单x等
        您好，明天只有是在[时间x]才能购买 
        ['[金额x]号我都要上班通班', 
        '第二个是纳税人识别号[SEP]咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x]', 
        '这个我需要明天[金额x]号安装', 
        '[订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]][SEP]您好[SEP]您好',
        '我申请退款[SEP]现在还需要我反馈[SEP]怎么反馈啊[SEP]我都拍了照片了[SEP]咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x][SEP]如何反馈?',
        '手机屏幕失灵了，去哪里修理[SEP][订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]]', 
        '咨询订单号:[订单x]订单金额:[金额x]下单时间:[日期x][SEP]我的快递到配送站了。我过几天去自提可以吗?', 
        '纳税识别号:[数字x]F[SEP]申请售后订单编号:[订单x]下单时间:[日期x][时间x][SEP]上面这个是激光笔的订单号', 
        '[订单编号:[订单x]，订单金额:[金额x]，下单时间:[日期x][时间x]][SEP]我怎样修改增票资质[SEP]您好[SEP]您好', 
        '东西是奶要不就等明天送了[SEP][日期x][时间x]订单编号:[数字x]订单金额:￥[金额x]']

step-2: 首先 jieba分词user_dict里面添加 替换词 不能切分。 然后，清除对话里面的冗余的相似问题。
    1. 添加user_dict后，lda 召回率97.7%
    2. 去除相似的  去除之后  98.1% (一些只包含 谢谢，好的 这种字样的 custom 句子) 共去除了515行。
    
    错误分析：
    wrong recall
    你可以催哈单么 | 体脂秤是电池的？ | 当然啊[SEP]等着呢 | 长虹和美菱共用的 | 就这样吧，涮我倒霉 | 啤酒[SEP]百威 | 那帮我有的先发吧  | 爱你哦么么哒  | 还是要自己配 | 能认识你，也是我的荣幸 | 不需要了，谢谢您 
        ['我收到商品不知道怎么使用', '我买的数据线充不进去电', '好的[SEP]我现在在学校里，地址有变', '四川省***', '[数字x]能用吗', '什么时候活动', '最多能叠加多少[SEP]用户发起转人工', '店铺劵都有啥', '最多能减多少', 'Ub[数字x]']
    好的[SEP]谢谢  | 对[SEP]可以  | 好的[姓名x] |好的[SEP]谢谢呢 
    没[SEP]谢谢 | 没有了[SEP]谢谢 
        ['其他没有了，[SEP]谢谢', '没有了谢谢[SEP]五星', '没有啦[SEP]谢谢你', 'OK，谢谢[SEP]没有了', '没有了这些[SEP]谢谢', '没有了，我就静候佳音吧[SEP]谢谢', '没有了，[SEP]谢谢', '没有了，等你的信[SEP]谢谢', '谢谢🙏[SEP]没有了', 'ok，没有了[SEP]谢谢']

    。。。[数字x]天也太久了。 
        ['[数字x]天了呀', '嗯，就他自己生成的就是[数字x]天的吧', '超过[数字x]天了', '[数字x]天了', '那就延[数字x]天', '[数字x]W多', 'g[数字x]e', '[数字x]天', '[数字x]W', '北宿矿安居北区[数字x]号楼']



### 方法4： word2vec + tfidf　权重　召回率99.9%

相同的问题在TOP10里面可以准确召回，但是需要分析召回其他的内容 是否真的相似。
唯一的一个错误召回，只是index与query不一样而已，内容其实一样。
recall : 0.999
2020-11-12 18:35:13 - INFO - sentenceSimilarity - recall_at_10: 0.999
wrong recall
没有了，谢谢
['没有，谢谢。', '没有其他了，谢谢。', '没有了，谢谢啦。', '谢谢，没有了', '没有了，谢谢哦', '谢谢啦，没有了', '没有。谢谢你', '没有了。谢谢你了。', '谢谢，没有啦', '其他没有，谢谢']


用户输入体验：
请输入问题(q退出): 我 的订单啥时候发呀
2020-11-12 19:51:11 - INFO - sentenceSimilarity - Searching for 我的订单啥时候发呀
2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - collecting document frequencies
2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - PROGRESS: processing document #0
2020-11-12 19:51:11 - INFO - gensim.models.tfidfmodel - calculating IDF weights for 10000 documents and 3125 features (63731 matrix non-zeros)
[(77, 1), (350, 1)] [(77, 0.37828451813959335), (350, 0.9256893773485227)]
['订单', '啥时候', '发呀']
亲，我们给您找到的答案是： [站点x]您的订单正在配送途中，请您准备签收(配送员:[姓名x]，电话:[电话x])，感谢您的耐心等待。[SEP]这个已经邮寄到了呢[SEP]您这边直接联系配送就是可以的哈
Time cost: 0.016529321670532227 s
same questions： 是这一个订单~,                distance: 0.0005517895333468914
same questions： 你好，订单的发票别忘了,                distance: 0.0011370766442269087
same questions： [订单x][SEP]很忙吗?,                distance: 0.0022505568340420723
same questions： 这个订单签收了,                distance: 0.002779792295768857
same questions： 如果收货人信息,                distance: 0.002916591241955757

### 所以召回结果的评估？

对于召回的内容如何评估，可以用文本相似度匹配模型。进行召回结果的分析。