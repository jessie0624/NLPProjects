# FQA 

## Description

FQA是一个简单的基于检索的客户问答系统. 该系统包含2个模块: 业务咨询和闲聊.

- 业务咨询: 基于检索
- 闲聊: 基于生成模型

FQA的模型架构:

1. 通过分类模型,判断用户输入是业务咨询 还是 闲聊.
2. 如果是业务咨询,进入咨询模型.
3. 如果是闲聊,进入闲聊模块

## FQA模块采用技术以及未来优化空间
#### 1. 判断用户输入为咨询业务还是闲聊

folder: intention
目前采用: FastText 做二分类.  
    
    可优化地方:

    1. 分类模型为: 目前采用的FastText 做文本分类, 这个方法很简单, 效果一般. 目前只有95%.
        优化方法: 1. 调参看结果, 2.采用更复杂的模型, 或者ensemble 模型等.  
        ING 正在改进 ensemble 模型

    2. 目前只是一个简单的二分类,可以做成多分类,比如业务咨询是哪方面业务,或者 闲聊方面闲聊等. TODO 待定.
   
#### 2. 信息检索模块

该模块分为2部分:

- 基于用户问题与数据库问题的相似度匹配. 
  
  该模块分为3步骤:  1 相似问题召回 HNSW,  2 问题与问题之间相似度计算  3 问题相似度细排得到top5相似问题

- 基于用户问题与top5 相似问题的答案的匹配.  
  
  该模块主1步: 1 通过上一步得到的top5相似问题　从数据库获取这些问题的答案，　进行用户问题与５个答案的距离计算，　得分高的作为返回结果．
    
        

1. 召回算法：

尝试算法如下：  训练集100000(100k的问题-答案对儿)
- tfidf 句向量表示，根据关键词召回，top10召回率99.9%。唯一一个没有召回成功的是： 用户问题为： 你可以催哈单么 。。。 这个句子无法 召回。
- lsi  top10召回率99.9%。与TFIDF效果一样
- lda　主题模型召回，top10 召回率98.1%。召回错误的 是问题与整个客服问答系统 不相关的问题。主要原因是 问句 里面含有的关键词词频较低。在lda模型里面无法找到匹配的主题。
- tfidf + reversedIndex:  相比之前的单纯的index, 单个问题速度快了1倍， 数据集比较小，体现不够明显
- word2vec + tfidf + HNSW: 速度明显比之前快10倍左右，上面几种方式tt=0.1-0.2，用HNSW 时间在0.01-0.02之间。 召回率98.3%
- word2vec + HNSW: 
- word2vec + SIF + HNSW: 


2. 相似度计算:

- 深度学习模型:  目前采用基于BERT point wise的 文本相似度匹配的模型,进行训练. 目前准确率为92%, 继续优化还可以提升.
- 基本相似度计算字符级别的:  lcs 最长公共子串, jaccard 距离, edit dist.  
- 基本文本相似度计算: bm25, 基于 w2v, fasttext 词向量的构造的句向量的 eurl, pearson, wmd.

3. 重排

- 将上述特征计算出的得分, 组合起来, 作为lightGBM 的训练特征, 进行排序训练.　取ｔop5相似的问题．

4. 用户问题与相似问题的答案匹配

- 深度学习模型：此处用BERT训练　是否为正确答案的　pairwise的模型. 目前准确率为97.89%
- refer: 将用户问题与相似问题的答案 组成pair 作为模型的输入, 获取得分最高的 答案作为返回.


#### 3. 闲聊生成模块

    目前采用seq2seq + attention 实现简单的对话.
    正在实现基于GPT2的中文对话.

#### 4. 整合任务pipeline
整合任务型对话模块 task.py

    先做意图识别, 筛选业务性查询.

    然后对业务性查询进行召回.

    对召回结果进行排序.

    返回正确答案.

    
