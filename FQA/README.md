# FQA 

## Description

FQA是一个简单的基于检索的客户问答系统. 该系统包含2个模块: 业务咨询和闲聊.

- 业务咨询: 基于检索
- 闲聊: 基于生成模型

FQA的模型架构:

1. 通过分类模型,判断用户输入是业务咨询 还是 闲聊.
2. 如果是业务咨询,进入咨询模型.
3. 如果是闲聊,进入闲聊模块

## FQA模块采用技术以及未来优化空间

1. 判断用户输入为咨询业务还是闲聊

    folder: intention
    目前采用: FastText 做二分类. 通过代码对对话数据集进行自动标注, 根据用户咨询中是否包含关键词来判断是否为业务咨询.
    可优化地方:
        1. 关键词提取方法: 目前根据pesg分词,提取用户咨询里面的名词,动名词等, 这是最简单粗暴的方式.  
            优化方法: 根据句法分析, 提取关键词. 可以尝试一下. TODO
        2. 分类模型为: 目前采用的FastText 做文本分类, 这个方法很简单, 效果一般.
            优化方法: 1. 调参看结果, 2.采用更复杂的模型, 或者ensemble 模型等.  TODO
        3. 数据标注方法: 目前根据是否含有关键词, 进行标注, 可能步准确. 
            优化方法: 人工标注(目前做不到)
        4. 目前只是一个简单的二分类,可以做成多分类,比如业务咨询是哪方面业务,或者 闲聊方面闲聊等. TODO 待定.
   
2. 信息检索模块

    folder: retrieval + ranking

    该模块分为3部分, 1 构造句向量, 2 召回粗排, 3 提取细排

    2.1 句向量表示: 

        目前采用 word2vec 在对话语料上训练300维词向量. 句向量通过wam(word average model)计算得到.

        优化空间: 1. 句向量可以用bert 得到, 或者通过TFIDF加权模式得到句向量等.TODO 
    
    2.2 召回粗排: 

        目前采用 Faiss的HNSW库,对用户的问题进行粗排,召回.

        优化空间: 1. 调参. 
                 2. 在句向量中加上规则 权重等信息. 
                 3. 降维(目前句向量是300维度,HNSW有点慢,可以用PCA降维) TODO.  
                 4. 倒排索引(学一下). (可以参考: https://github.com/liqima/faiss_note 看有没有优化方案)

        粗排目标在于 快, 高召回率. top100 或者 top1000达到99%-100% 召回率.

    2.3 提取细排:

        目前采用:

3. 闲聊生成模块:
    



### 细排模块

1. 处理数据集用于做相似度匹配. ranking/data.py
2. 人工特征: bm25, train_LM 在训练集上训练几个模型: TFIDF, BM25, word2vec, FastText.
   构建相似度特征: ranking/similarity.py
3. 深度匹配:训练一个bert模型对输入的两个问题做序列相似度匹配,得到一个相似度分数. ranking/train_matchnn.py
4. 排序: 利用前面步骤的特征,使用LightGBM 来训练排序模型. ranking/ranker.py(RANK do_train=True 训练, do_train=False 预测)
5. 整合任务型对话模块: 
    先做意图识别, 筛选业务性查询.
    然后对业务性查询进行召回.
    对召回结果进行排序.

